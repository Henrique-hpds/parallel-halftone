\label{sec:speedup}

Nesta seção, apresentamos as métricas de Speedup obtidas durante os experimentos. O Speedup é calculado como a razão entre o tempo de execução da versão serial e o tempo de execução das versões paralelas (OpenMP e CUDA). Foram consideradas duas abordagens principais:

\begin{itemize}
    \item \textbf{Speedup por Método:} Para cada método de dithering (\textit{FloydSteinberg}, \textit{StevensonArce}, \textit{Burkes}, \textit{Sierra}, \textit{Stucki}, \textit{JarvisJudiceNinke}), calculamos o Speedup médio considerando todas as imagens processadas.
    \item \textbf{Speedup por Tamanho de Imagem:} Para cada tamanho de imagem (\textit{e.g.}, 1920x1080, 1280x720), calculamos o Speedup médio considerando todos os métodos de dithering aplicados. Os tamanhos de imagem foram classificados em quatro categorias:
        \begin{itemize}
            \item \textbf{Pequeno (small):} Imagens com largura e altura menores ou iguais a 256 pixels.
            \item \textbf{Médio (medium):} Imagens com largura e altura menores ou iguais a 512 pixels.
            \item \textbf{Grande (large):} Imagens com largura e altura menores ou iguais a 1024 pixels.
            \item \textbf{Muito Grande (xlarge):} Imagens com largura ou altura maiores que 1024 pixels.
        \end{itemize}
\end{itemize}

Os resultados obtidos estão destacados nas Tabelas das subceções a seguir.

\subsection{Ambiente de Teste}

    O Benchmarkingfoi realizado em um sistema com as seguintes especificações:
    \begin{itemize}
        \item \textbf{Processador:} Intel Core i7-11800H
        \item \textbf{Memória RAM:} 16 GB DDR4
        \item \textbf{Placa de Vídeo:} NVIDIA GeForce RTX 3060 80W
        \item \textbf{Versão do CUDA:} 12.9
        \item \textbf{Driver NVIDIA:} 575.64
        \item \textbf{Compilador C/C++:} GCC 15.1.1
        \item \textbf{Versão do OpenMP:} 4.5
        \item \textbf{Sistema Operacional:} Arch Linux (rolling release)
        \item \textbf{Versão do kernel:} 6.15.4-arch2-1
    \end{itemize}

    Para a coleta de dados, utilizamos o \texttt{omp\_get\_wtime()} para medir o tempo de execução dos códigos. O método de dithering aplicado é passado via linha de comando (como especificado no README do projeto). Todos os dados foram coletados utilizando \textit{grayscale} ativado. O método de dithering base para medição de impacto de acordo com o tamanho da imagem é o \textit{FloydSteinberg}. As imagens utilizadas foram obtidas do repositório oficial do projeto, conforme descrito no README.

    Organizamos um script de benchmarking, que executa cada imagem 5 vezes, onde conseguigmos alterar o método de dithering, flag de método estocástico e flag de escala de cinza. O script foi implementado em \texttt{colab-runner.ipynb} na raiz do repositório. 
\subsection{Resultados}

\begin{table}[H]
\centering
\caption{Resultados de Speedup por Método}
\label{tab:speedup_methods}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Método} & \textbf{Serial (ms)} & \textbf{OpenMP (ms)} & \textbf{CUDA (ms)} & \textbf{Speedup OpenMP} & \textbf{Speedup CUDA} \\ \hline
FloydSteinberg & $126.52 \pm 301.72$ & $25.08 \pm 47.89$ & $146.27 \pm 317.29$ & $5.04 \pm 15.41$ & $0.86 \pm 2.79$ \\ \hline
StevensonArce & $311.94 \pm 748.04$ & $57.94 \pm 122.09$ & $146.80 \pm 317.41$ & $5.38 \pm 12.91$ & $2.12 \pm 6.86$ \\ \hline
Burkes & $191.00 \pm 455.59$ & $38.36 \pm 82.35$ & $146.64 \pm 318.72$ & $4.98 \pm 15.98$ & $1.30 \pm 4.20$ \\ \hline
Sierra & $262.05 \pm 619.44$ & $48.04 \pm 102.86$ & $145.37 \pm 318.33$ & $5.45 \pm 17.40$ & $1.80 \pm 5.81$ \\ \hline
Stucki & $309.84 \pm 739.82$ & $53.09 \pm 112.06$ & $145.15 \pm 317.87$ & $5.84 \pm 21.18$ & $2.13 \pm 6.92$ \\ \hline
JarvisJudiceNinke & $305.95 \pm 720.93$ & $56.04 \pm 124.03$ & $147.02 \pm 317.46$ & $5.46 \pm 33.53$ & $2.08 \pm 6.65$ \\ \hline
\end{tabular}
\end{table}

A incerteza associada nos tempos de execução e no speedup foram bastante altas. Isso aconteceu pois na gama de testes realizados, as implementações receberam imagens de tamanhos variados (de small a xlarge). Por conta dessa imprecisão, a tabela \ref{tab:speedup_stochastic} não inclui as incertezas, contentando apenas os valores médios de Speedup.

\begin{table}[H]
\centering
\caption{Resultados de Speedup por Tamanho de Imagem}
\label{tab:speedup_sizes}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Tamanho da Imagem} & \textbf{Serial (ms)} & \textbf{OpenMP (ms)} & \textbf{CUDA (ms)} & \textbf{Speedup OpenMP} & \textbf{Speedup CUDA} \\ \hline
Small & $4.57 \pm 0.78$  & $3.81 \pm 2.81$ & $7.76 \pm 0.95$ & $1.20 \pm 0.91$ & $0.59 \pm 0.12$ \\ \hline
Medium & $21.20 \pm 0.78$& $7.71 \pm 3.25$ & $30.65 \pm 2.33$ & $2.75 \pm 1.16$ & $0.69 \pm 0.08$ \\ \hline
Large & $37.90 \pm 19.62$ & $10.66 \pm 4.04$ & $58.64 \pm 26.64$ & $3.56 \pm 2.06$ & $0.65 \pm 0.45$ \\ \hline
Extra Large & $345.02 \pm 486.16$ & $61.30 \pm 75.79$ & $380.57 \pm 507.17$ & $5.63 \pm 8.30$ & $0.91 \pm 1.76$ \\ \hline
\end{tabular}
\end{table}

Quando analisamos um em uma escala mais controlada de tamanho de imagem, vemos que as incertezas diminuem, ressaltando a análise sobre a tabela anterior. Vemos que o CUDA não apresenta um bom speedup e uma Occupancy extremamente baixa, o que pode ser explicado pelo fato de que nessa implementação, o dado possui dependência espacial, ou seja, apresenta baixo paralelismo.


\begin{table}[H]
\centering
\caption{Resultados de Eficiência por Método}
\label{tab:efficiency_methods}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Método} & \textbf{Eficiência OpenMP} & \textbf{Occupancy CUDA (\%)} \\ \hline
FloydSteinberg & $0.32$ & $2.08$ \\ \hline
StevensonArce & $0.34$ & $2.08$ \\ \hline
Burkes & $0.31$ & $2.08$ \\ \hline
Sierra & $0.34$ & $2.08$ \\ \hline
Stucki & $0.37$ & $2.08$ \\ \hline
JarvisJudiceNinke & $0.34$ &$2.08$  \\ \hline
\end{tabular}
\end{table}

Utilizando as medições para o método \textit{FloydSteinberg} como base, vamos analisar a eficiência do OpenMP em relação ao tamanho da imagem.

\begin{table}[H]
\centering
\caption{Resultados de Eficiência do OpenMP por Tamanho de Imagem}
\label{tab:efficiency_sizes}
\begin{tabular}{|c|c|}
\hline
\textbf{Tamanho da Imagem} & \textbf{Eficiência OpenMP} \\ \hline
Small &  0.08 \\ \hline
Medium & 0.17 \\ \hline
Large & 0.22 \\ \hline
Extra Large & 0.35 \\ \hline
\end{tabular}
\end{table}

\subsection{Método estocástico}

    Os códigos de OpenMP e CUDA possuíam uma flag que permitia a utilização de um método estocástico. Esse método introduz variações aleatórias no processo de dithering, o que pode impactar os resultados de Speedup e Eficiência. Durante os experimentos, observamos que o uso do método estocástico gerou diferenças nos tempos de execução e nos resultados finais. No entanto, como o objetivo do processo de dithering é criar um efeito visual na imagem, essas variações não comprometem a qualidade visual do resultado, tornando válida a sua utilização.


    \begin{figure}[H]
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{figures/comparacao/input.png}
            \caption{Imagem Original}
            \label{fig:input_image}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{figures/comparacao/openmp.png}
            \caption{OpenMP}
            \label{fig:openmp_image}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{figures/comparacao/openmp_stochastic.png}
            \caption{OpenMP Estocástico}
            \label{fig:openmp_stochastic_image}
        \end{subfigure}
        \caption{Comparação visual entre as imagens: original, OpenMP e OpenMP com método estocástico.}
        \label{fig:comparison_images}
    \end{figure}

    Os resultados obtidos com o método estocástico foram considerados satisfatórios. Apesar das variações introduzidas no processo de dithering, a qualidade visual das imagens geradas permaneceu consistente com os objetivos do experimento. A Figura~\ref{fig:comparison_images} ilustra que as diferenças visuais entre as imagens processadas com e sem o método estocástico são mínimas, reforçando a validade do uso dessa abordagem nos experimentos realizados.

    Diferente de antes, vamos apresentar os resultados sem levar em consideração à incerteza associada, a fim de evitar a redundância de informação sobre as diferenças dos tamanhos de imagens. É aceitável que os resultados sejam apresentados sem considerar a incerteza, uma vez que o foco é comparar os métodos de dithering e suas implementações paralelas de forma geral. 

    % Talvez seja interessante criar uma tabela com os resultados de tempos,
    % e após isso, criar uma outra tabela com os resultados do speedup,
    % considerando a média total de todos os métodos.
    % Tabela de tempos absolutos para o método estocástico
    \begin{table}[H]
        \centering
        \caption{Tempos Médios de Execução para o Método Estocástico}
        \label{tab:tempos_stochastic}
        \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Método} & \textbf{Serial (ms)} & \textbf{OpenMP (ms)} & \textbf{CUDA (ms)} \\ \hline
        FloydSteinberg & $795.46$ & $110.73$ & $0.42$ \\ \hline
        StevensonArce & $2220.53$ & $298.43$ & $0.54$ \\ \hline
        Burkes & $1310.33$ & $125.78$ & $0.45$ \\ \hline
        Sierra & $1852.19$ & $246.34$ & $0.49$ \\ \hline
        Stucki & $2204.74$ & $284.48$ & $0.52$ \\ \hline
        JarvisJudiceNinke & $2213.28$ & $284.34$ & $0.52$ \\ \hline
        \end{tabular}
    \end{table}

        Como o tempo de execução do método estocástico do serial foi muito maior que a implementação comum, vamos utilizar a implementação não estocástica como base a tabela [\ref{tab:speedup_methods}] para o cálculo do Speedup e Eficiência. 
    % Tabela de speedup para o método estocástico
    \begin{table}[H]
        \centering
        \caption{Speedup para o Método Estocástico}
        \label{tab:speedup_stochastic}
        \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Método} & \textbf{Speedup OpenMP} & \textbf{Speedup CUDA} \\ \hline
        FloydSteinberg & $1.14$ & $301.24$ \\ \hline
        StevensonArce & $1.04$ & $577.67$ \\ \hline
        Burkes & $1.03$ & $424.44$ \\ \hline
        Sierra & $1.06$ & $534.80$ \\ \hline
        Stucki & $1.09$ & $595.85$ \\ \hline
        JarvisJudiceNinke & $1.07$ & $588.37$ \\ \hline
        \end{tabular}
    \end{table}

    \begin{table}[H]
    \centering
    \caption{Resultados de Eficiência para o Método Estocástico}
    \label{tab:efficiency_stochastic}
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Método} & \textbf{Eficiência OpenMP} & \textbf{Ocuppancy CUDA (\%)} \\ \hline
    FloydSteinberg & $0.07$ & $61.65$ \\ \hline
    StevensonArce & $0.07$ & $60.90$ \\ \hline
    Burkes & $0.06$ & $59.68$ \\ \hline
    Sierra & $0.07$ & $59.54$ \\ \hline
    Stucki & $0.07$ & $59.90$ \\ \hline
    JarvisJudiceNinke & $0.07$ & $61.01$ \\ \hline
    \end{tabular}
    \end{table}

    Vemos que a Occupancy aumentou significativamente, e com isso, o speedup obtido com o CUDA foi muito maior que as outras implementações.

   \subsection{Análise de WSNR}

        Para avaliar a qualidade das imagens processadas pelas diferentes versões do código, utilizamos o script \texttt{wsnr.py}, que calcula a métrica WSNR (Weighted Signal-to-Noise Ratio). Essa métrica é amplamente utilizada para medir a qualidade de imagens processadas, levando em consideração o ruído introduzido durante o processamento.

        A seguir, apresentamos os resultados obtidos para cada método (serial, OpenMP e CUDA), organizados por tamanho de imagem:

        \subsubsection*{Tabela de Resultados WSNR por Método e Tamanho de Imagem}

        \begin{table}[H]
            \centering
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                \textbf{Tamanho} & \textbf{Imagem} & \textbf{CUDA (dB)} & \textbf{OpenMP (dB)} & \textbf{Serial (dB)} \\ \hline
                \multirow{2}{*}{Small} 
                & small\_1 & 0.6595 & -0.1043 & -0.1279 \\ \cline{2-5}
                & small\_2 & 1.1523 & 0.6237 & 0.5631 \\ \hline
                \multirow{8}{*}{Medium} 
                & medium\_1 & 1.2968 & 0.8956 & 0.9051 \\ \cline{2-5}
                & medium\_2 & 1.2322 & 0.9434 & 0.8777 \\ \cline{2-5}
                & medium\_3 & 0.6089 & 0.2502 & 0.2566 \\ \cline{2-5}
                & medium\_4 & 0.7146 & 0.3194 & 0.2924 \\ \cline{2-5}
                & medium\_5 & 1.7778 & 0.7717 & 0.7879 \\ \cline{2-5}
                & medium\_6 & 1.3159 & 0.8904 & 0.8921 \\ \cline{2-5}
                & medium\_7 & 1.2963 & 0.7031 & 0.6980 \\ \cline{2-5}
                & medium\_8 & -0.2986 & -0.8768 & -0.8693 \\ \hline
                \multirow{5}{*}{Large} 
                & large\_1 & 0.0847 & -0.0862 & -0.0905 \\ \cline{2-5}
                & large\_2 & 1.6083 & 0.8550 & 0.8642 \\ \cline{2-5}
                & large\_3 & 1.6087 & 0.8773 & 0.8754 \\ \cline{2-5}
                & large\_4 & 0.7675 & 0.7062 & 0.6588 \\ \cline{2-5}
                & large\_5 & -0.3377 & -0.8666 & -0.8857 \\ \hline
                \multirow{7}{*}{Xlarge} 
                & xlarge\_1 & 1.6322 & 0.8531 & 0.8586 \\ \cline{2-5}
                & xlarge\_2 & 1.6904 & 0.9132 & 0.9014 \\ \cline{2-5}
                & xlarge\_3 & 1.6817 & 0.8648 & 0.8632 \\ \cline{2-5}
                & xlarge\_4 & 1.6876 & 0.9090 & 0.9010 \\ \cline{2-5}
                & xlarge\_5 & 0.7856 & 0.4889 & 0.4997 \\ \cline{2-5}
                & xlarge\_6 & 2.3256 & 1.3715 & 1.3500 \\ \cline{2-5}
                & xlarge\_7 & 0.8412 & 0.1943 & 0.2099 \\ \hline
                \multicolumn{2}{|c|}{\textbf{Média WSNR}} & \textbf{1.0969} & \textbf{0.5226} & \textbf{0.5128} \\ \hline
            \end{tabular}
            \caption{Resultados WSNR por Método e Tamanho de Imagem}
        \end{table}
        \subsubsection*{Interpretação dos Resultados}
        A métrica WSNR indica a relação entre o sinal e o ruído introduzido no processamento das imagens. Valores mais altos de WSNR indicam menor degradação da qualidade da imagem. Observa-se que a versão CUDA apresenta a maior média de WSNR (1.0969 dB), seguida pela versão OpenMP (0.5226 dB) e pela versão serial (0.5128 dB). Isso sugere que a versão CUDA não apenas é mais eficiente em termos de desempenho, mas também preserva melhor a qualidade das imagens processadas.