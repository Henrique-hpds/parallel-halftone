Este trabalho explorou diferentes estratégias para a paralelização de algoritmos de difusão de erro, com foco nos métodos clássicos da literatura. Foram desenvolvidas três versões: uma serial, uma paralela utilizando OpenMP e uma versão em CUDA, além da inclusão de uma abordagem estocástica que introduz aleatoriedade no processo de quantização.

A avaliação de desempenho dos métodos convencionais mostra que a paralelização com OpenMP é capaz de gerar speedups significativos em relação à versão serial, especialmente para imagens grandes. Em média, os speedups variaram de 4.9x a 5.8x, com destaque para o método Stucki (5.84x) e Sierra (5.45x). Já a versão CUDA, surpreendentemente, apresentou desempenho inferior ao esperado para GPUs. Isso se deve, principalmente, à baixa ocupação da GPU (2.08\%) em todos os métodos, sugerindo subutilização dos recursos, sendo uma consequência do baixo paralelismo na implementação tradicional (forte dependência espacial entre os pixels).

Ao analisarmos por tamanho de imagem, o OpenMP teve eficiência crescente com a resolução, indo de 0.08 (imagens pequenas) até 0.35 (imagens extra grandes). Isso confirma que o OpenMP é mais eficaz em ambientes com grande volume de dados, mas seu ganho é limitado em imagens pequenas devido ao overhead de paralelização. Já o CUDA apresentou speedups abaixo de 1.0 em imagens pequenas e médias, atingindo no máximo 0.91x em imagens extra grandes, refletindo a ineficiência geral da sua implementação convencional.

O cenário muda completamente com os métodos estocásticos. Nessa abordagem, a implementação CUDA se destaca, apresentando speedups de mais de 500x, com ocupação da GPU superior a 59\%. O método Stucki, por exemplo, obteve speedup de 595.85x, enquanto Jarvis Judice Ninke chegou a 588.37x, um salto em relação à versão determinística. Isso mostra que a estrutura de paralelismo da GPU foi muito melhor aproveitada na distribuição de erro estocástica, devido a redução de dependências e a melhor distribuição de carga.

Já o OpenMP estocástico teve desempenho significativamente inferior ao esperado, com speedups entre 1.03x e 1.14x, indicando que a inserção de aleatoriedade causou perda de paralelismo efetivo. Sua eficiência ficou em torno de 0.06 a 0.07, muito abaixo da eficiência obtida nos métodos convencionais.

No aspecto visual, a análise de WSNR mostrou que a versão CUDA apresentou a maior fidelidade média (1.10 dB), seguida por OpenMP (0.52 dB) e Serial (0.51 dB), sugerindo que o uso da GPU não só acelerou a execução, como preservou (ou até melhorou) a qualidade da imagem. A variação introduzida pelo método estocástico não comprometeu a aparência final, validando seu uso em aplicações práticas.